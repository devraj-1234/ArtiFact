{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f179991e",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ Compute Optimal Restoration Parameters\n",
    "\n",
    "**Goal**: For each damaged/undamaged image pair, find the optimal color correction and sharpening parameters that maximize similarity.\n",
    "\n",
    "**What we'll do**:\n",
    "1. Load paired dataset (damaged + undamaged)\n",
    "2. For each pair, test different restoration parameter combinations\n",
    "3. Measure similarity using PSNR and SSIM\n",
    "4. Record optimal parameters that give highest similarity\n",
    "5. Create training dataset: [14 FFT features] â†’ [optimal parameters]\n",
    "\n",
    "**Output**: CSV with features + optimal restoration parameters for regression training\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4756621b",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e3cca98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "# Import our modules\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.basics.optimized_restoration import restore_image_optimized\n",
    "from src.ml.feature_extractor import extract_ml_features\n",
    "\n",
    "print('âœ… All libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c2dfb1",
   "metadata": {},
   "source": [
    "## ðŸ“‚ Step 2: Load Paired Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5b181ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Dataset Statistics:\n",
      "======================================================================\n",
      "Damaged images found: 114\n",
      "Undamaged images found: 114\n",
      "Matching pairs: 112\n",
      "\n",
      "First 5 pairs: ['1.png', '10.png', '100.png', '101.jpg', '102.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Paths to damaged and undamaged images\n",
    "damaged_dir = '../data/raw/AI_for_Art_Restoration_2/paired_dataset_art/damaged'\n",
    "undamaged_dir = '../data/raw/AI_for_Art_Restoration_2/paired_dataset_art/undamaged'\n",
    "\n",
    "# Get list of image pairs\n",
    "damaged_files = sorted([f for f in os.listdir(damaged_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "undamaged_files = sorted([f for f in os.listdir(undamaged_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "\n",
    "# Find matching pairs\n",
    "paired_files = [f for f in damaged_files if f in undamaged_files]\n",
    "\n",
    "print(f'ðŸ“Š Dataset Statistics:')\n",
    "print('='*70)\n",
    "print(f'Damaged images found: {len(damaged_files)}')\n",
    "print(f'Undamaged images found: {len(undamaged_files)}')\n",
    "print(f'Matching pairs: {len(paired_files)}')\n",
    "print()\n",
    "print(f'First 5 pairs: {paired_files[:5]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d23d3fa",
   "metadata": {},
   "source": [
    "## ðŸ” Step 3: Define Parameter Search Space\n",
    "\n",
    "We'll test different combinations of restoration parameters to find what works best for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34e04243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Parameter Search Space:\n",
      "======================================================================\n",
      "Color correction methods: ['white_balance', 'none']\n",
      "Sharpening sigma values: [0.5, 1.0, 1.5, 2.0]\n",
      "Sharpening strength values: [0.5, 1.0, 1.5, 2.0, 2.5]\n",
      "\n",
      "Total parameter combinations to test: 40\n",
      "Total evaluations: 4480\n"
     ]
    }
   ],
   "source": [
    "# Parameter ranges to test\n",
    "# We'll test a grid of parameters and find the best combination\n",
    "\n",
    "COLOR_METHODS = ['white_balance', 'none']  # none means skip color correction\n",
    "SHARPEN_SIGMA = [0.5, 1.0, 1.5, 2.0]  # Gaussian blur sigma\n",
    "SHARPEN_STRENGTH = [0.5, 1.0, 1.5, 2.0, 2.5]  # Sharpening intensity\n",
    "\n",
    "print('ðŸŽ¯ Parameter Search Space:')\n",
    "print('='*70)\n",
    "print(f'Color correction methods: {COLOR_METHODS}')\n",
    "print(f'Sharpening sigma values: {SHARPEN_SIGMA}')\n",
    "print(f'Sharpening strength values: {SHARPEN_STRENGTH}')\n",
    "print()\n",
    "total_combinations = len(COLOR_METHODS) * len(SHARPEN_SIGMA) * len(SHARPEN_STRENGTH)\n",
    "print(f'Total parameter combinations to test: {total_combinations}')\n",
    "print(f'Total evaluations: {len(paired_files) * total_combinations}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c584cab",
   "metadata": {},
   "source": [
    "## ðŸ§ª Step 4: Find Optimal Parameters for Each Image Pair\n",
    "\n",
    "For each damaged image:\n",
    "1. Try all parameter combinations\n",
    "2. Apply restoration\n",
    "3. Compare with ground truth (undamaged image)\n",
    "4. Record parameters that give highest PSNR + SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f042fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Similarity function defined!\n"
     ]
    }
   ],
   "source": [
    "def compute_similarity_score(restored, undamaged):\n",
    "    \"\"\"\n",
    "    Compute combined similarity score using PSNR and SSIM.\n",
    "    \n",
    "    Args:\n",
    "        restored: Restored image\n",
    "        undamaged: Ground truth undamaged image\n",
    "    \n",
    "    Returns:\n",
    "        score: Combined score (higher is better)\n",
    "        psnr_val: PSNR value\n",
    "        ssim_val: SSIM value\n",
    "    \"\"\"\n",
    "    # Resize images to same size if needed\n",
    "    if restored.shape != undamaged.shape:\n",
    "        restored = cv2.resize(restored, (undamaged.shape[1], undamaged.shape[0]))\n",
    "    \n",
    "    # Calculate PSNR (higher is better, typically 20-50 dB)\n",
    "    psnr_val = psnr(undamaged, restored)\n",
    "    \n",
    "    # Calculate SSIM (higher is better, 0-1 range)\n",
    "    # For color images, compute SSIM per channel and average\n",
    "    if len(restored.shape) == 3:\n",
    "        ssim_val = ssim(undamaged, restored, channel_axis=2, data_range=255)\n",
    "    else:\n",
    "        ssim_val = ssim(undamaged, restored, data_range=255)\n",
    "    \n",
    "    # Combined score: normalize PSNR (divide by 50) and weight both metrics equally\n",
    "    # This gives a score roughly in 0-1 range\n",
    "    combined_score = 0.5 * (psnr_val / 50.0) + 0.5 * ssim_val\n",
    "    \n",
    "    return combined_score, psnr_val, ssim_val\n",
    "\n",
    "print('âœ… Similarity function defined!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75c67031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Parameter optimization function defined!\n"
     ]
    }
   ],
   "source": [
    "def find_optimal_parameters(damaged_path, undamaged_path):\n",
    "    \"\"\"\n",
    "    Find optimal restoration parameters for a damaged/undamaged image pair.\n",
    "    \n",
    "    Args:\n",
    "        damaged_path: Path to damaged image\n",
    "        undamaged_path: Path to undamaged image\n",
    "    \n",
    "    Returns:\n",
    "        best_params: Dictionary with optimal parameters\n",
    "        best_score: Best similarity score achieved\n",
    "        best_psnr: PSNR at best parameters\n",
    "        best_ssim: SSIM at best parameters\n",
    "    \"\"\"\n",
    "    # Load images\n",
    "    damaged = cv2.imread(damaged_path)\n",
    "    undamaged = cv2.imread(undamaged_path)\n",
    "    \n",
    "    if damaged is None or undamaged is None:\n",
    "        return None, 0, 0, 0\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = {}\n",
    "    best_psnr = 0\n",
    "    best_ssim = 0\n",
    "    \n",
    "    # Test all parameter combinations\n",
    "    for color_method in COLOR_METHODS:\n",
    "        for sigma in SHARPEN_SIGMA:\n",
    "            for strength in SHARPEN_STRENGTH:\n",
    "                try:\n",
    "                    # Apply restoration with these parameters\n",
    "                    if color_method == 'none':\n",
    "                        # Only sharpening, no color correction\n",
    "                        from src.basics.advanced_restoration import unsharp_mask\n",
    "                        restored = unsharp_mask(damaged.copy(), sigma=sigma, strength=strength)\n",
    "                    else:\n",
    "                        restored = restore_image_optimized(\n",
    "                            damaged.copy(),\n",
    "                            color_method=color_method,\n",
    "                            sharpen_sigma=sigma,\n",
    "                            sharpen_strength=strength\n",
    "                        )\n",
    "                    \n",
    "                    # Compute similarity with ground truth\n",
    "                    score, psnr_val, ssim_val = compute_similarity_score(restored, undamaged)\n",
    "                    \n",
    "                    # Update best parameters if this is better\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_psnr = psnr_val\n",
    "                        best_ssim = ssim_val\n",
    "                        best_params = {\n",
    "                            'color_method': color_method,\n",
    "                            'apply_color_correction': 1 if color_method != 'none' else 0,\n",
    "                            'sharpen_sigma': sigma,\n",
    "                            'sharpen_strength': strength\n",
    "                        }\n",
    "                \n",
    "                except Exception as e:\n",
    "                    continue\n",
    "    \n",
    "    return best_params, best_score, best_psnr, best_ssim\n",
    "\n",
    "print('âœ… Parameter optimization function defined!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ca2334d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Processing image pairs to find optimal parameters...\n",
      "======================================================================\n",
      "This may take several minutes...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing parameters:   0%|          | 0/20 [02:18<?, ?it/s]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m undamaged_path = os.path.join(undamaged_dir, filename)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Find optimal parameters\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m best_params, score, psnr_val, ssim_val = \u001b[43mfind_optimal_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdamaged_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mundamaged_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m best_params:\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m# Extract features from damaged image\u001b[39;00m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 46\u001b[39m, in \u001b[36mfind_optimal_parameters\u001b[39m\u001b[34m(damaged_path, undamaged_path)\u001b[39m\n\u001b[32m     38\u001b[39m     restored = restore_image_optimized(\n\u001b[32m     39\u001b[39m         damaged.copy(),\n\u001b[32m     40\u001b[39m         color_method=color_method,\n\u001b[32m     41\u001b[39m         sharpen_sigma=sigma,\n\u001b[32m     42\u001b[39m         sharpen_strength=strength\n\u001b[32m     43\u001b[39m     )\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# Compute similarity with ground truth\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m score, psnr_val, ssim_val = \u001b[43mcompute_similarity_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrestored\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mundamaged\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# Update best parameters if this is better\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m score > best_score:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mcompute_similarity_score\u001b[39m\u001b[34m(restored, undamaged)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Calculate SSIM (higher is better, 0-1 range)\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# For color images, compute SSIM per channel and average\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(restored.shape) == \u001b[32m3\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     ssim_val = \u001b[43mssim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mundamaged\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestored\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_axis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_range\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m255\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     26\u001b[39m     ssim_val = ssim(undamaged, restored, data_range=\u001b[32m255\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\skimage\\metrics\\_structural_similarity.py:142\u001b[39m, in \u001b[36mstructural_similarity\u001b[39m\u001b[34m(im1, im2, win_size, gradient, data_range, channel_axis, gaussian_weights, full, **kwargs)\u001b[39m\n\u001b[32m    140\u001b[39m _at = functools.partial(utils.slice_at_axis, axis=channel_axis)\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nch):\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     ch_result = \u001b[43mstructural_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim1\u001b[49m\u001b[43m[\u001b[49m\u001b[43m_at\u001b[49m\u001b[43m(\u001b[49m\u001b[43mch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim2\u001b[49m\u001b[43m[\u001b[49m\u001b[43m_at\u001b[49m\u001b[43m(\u001b[49m\u001b[43mch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gradient \u001b[38;5;129;01mand\u001b[39;00m full:\n\u001b[32m    144\u001b[39m         mssim[ch], G[_at(ch)], S[_at(ch)] = ch_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\skimage\\metrics\\_structural_similarity.py:275\u001b[39m, in \u001b[36mstructural_similarity\u001b[39m\u001b[34m(im1, im2, win_size, gradient, data_range, channel_axis, gaussian_weights, full, **kwargs)\u001b[39m\n\u001b[32m    272\u001b[39m pad = (win_size - \u001b[32m1\u001b[39m) // \u001b[32m2\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;66;03m# compute (weighted) mean of ssim. Use float64 for accuracy.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m mssim = \u001b[43mcrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m)\u001b[49m.mean(dtype=np.float64)\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gradient:\n\u001b[32m    278\u001b[39m     \u001b[38;5;66;03m# The following is Eqs. 7-8 of Avanaki 2009.\u001b[39;00m\n\u001b[32m    279\u001b[39m     grad = filter_func(A1 / D, **filter_args) * im1\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\skimage\\util\\arraycrop.py:12\u001b[39m, in \u001b[36mcrop\u001b[39m\u001b[34m(ar, crop_width, copy, order)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumbers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Integral\n\u001b[32m      9\u001b[39m __all__ = [\u001b[33m'\u001b[39m\u001b[33mcrop\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcrop\u001b[39m(ar, crop_width, copy=\u001b[38;5;28;01mFalse\u001b[39;00m, order=\u001b[33m'\u001b[39m\u001b[33mK\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     13\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Crop array `ar` by `crop_width` along each dimension.\u001b[39;00m\n\u001b[32m     14\u001b[39m \n\u001b[32m     15\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     39\u001b[39m \u001b[33;03m        view of the input array.\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     41\u001b[39m     ar = np.array(ar, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Process all image pairs and find optimal parameters\n",
    "print('ðŸ”„ Processing image pairs to find optimal parameters...')\n",
    "print('='*70)\n",
    "print('This may take several minutes...')\n",
    "print()\n",
    "\n",
    "results = []\n",
    "\n",
    "for filename in tqdm(paired_files[:20], desc='Optimizing parameters'):  # Start with 20 images for testing\n",
    "    damaged_path = os.path.join(damaged_dir, filename)\n",
    "    undamaged_path = os.path.join(undamaged_dir, filename)\n",
    "    \n",
    "    # Find optimal parameters\n",
    "    best_params, score, psnr_val, ssim_val = find_optimal_parameters(damaged_path, undamaged_path)\n",
    "    \n",
    "    if best_params:\n",
    "        # Extract features from damaged image\n",
    "        try:\n",
    "            features, feature_names = extract_ml_features(damaged_path)\n",
    "            \n",
    "            # Combine features and optimal parameters\n",
    "            result = {\n",
    "                'filename': filename,\n",
    "                'similarity_score': score,\n",
    "                'psnr': psnr_val,\n",
    "                'ssim': ssim_val,\n",
    "            }\n",
    "            \n",
    "            # Add features\n",
    "            for name, value in zip(feature_names, features):\n",
    "                result[name] = value\n",
    "            \n",
    "            # Add optimal parameters\n",
    "            result.update(best_params)\n",
    "            \n",
    "            results.append(result)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f'Error processing {filename}: {e}')\n",
    "\n",
    "print()\n",
    "print(f'âœ… Processed {len(results)} image pairs successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c568e9f",
   "metadata": {},
   "source": [
    "## ðŸ“Š Step 5: Analyze Optimal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55c2d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df_optimal = pd.DataFrame(results)\n",
    "\n",
    "print('ðŸ“Š Optimal Parameters Dataset:')\n",
    "print('='*70)\n",
    "print(f'Total samples: {len(df_optimal)}')\n",
    "print(f'Columns: {len(df_optimal.columns)}')\n",
    "print()\n",
    "print('Sample data:')\n",
    "df_optimal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d54e552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary of optimal parameters\n",
    "print('ðŸ“ˆ Statistical Summary of Optimal Parameters:')\n",
    "print('='*70)\n",
    "print()\n",
    "print('Similarity Metrics:')\n",
    "print(df_optimal[['similarity_score', 'psnr', 'ssim']].describe())\n",
    "print()\n",
    "print('Optimal Restoration Parameters:')\n",
    "print(df_optimal[['apply_color_correction', 'sharpen_sigma', 'sharpen_strength']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b846d1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize parameter distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Similarity metrics\n",
    "axes[0, 0].hist(df_optimal['similarity_score'], bins=20, color='#4ecdc4', edgecolor='black')\n",
    "axes[0, 0].set_title('Combined Similarity Score', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Score')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "axes[0, 1].hist(df_optimal['psnr'], bins=20, color='#ff6b6b', edgecolor='black')\n",
    "axes[0, 1].set_title('PSNR (dB)', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('PSNR')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "axes[0, 2].hist(df_optimal['ssim'], bins=20, color='#95e1d3', edgecolor='black')\n",
    "axes[0, 2].set_title('SSIM', fontweight='bold')\n",
    "axes[0, 2].set_xlabel('SSIM')\n",
    "axes[0, 2].set_ylabel('Frequency')\n",
    "\n",
    "# Optimal parameters\n",
    "axes[1, 0].hist(df_optimal['apply_color_correction'], bins=2, color='#ffeaa7', edgecolor='black')\n",
    "axes[1, 0].set_title('Color Correction Usage', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Apply (0=No, 1=Yes)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].set_xticks([0, 1])\n",
    "\n",
    "axes[1, 1].hist(df_optimal['sharpen_sigma'], bins=len(SHARPEN_SIGMA), color='#dfe6e9', edgecolor='black')\n",
    "axes[1, 1].set_title('Optimal Sharpen Sigma', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Sigma')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "axes[1, 2].hist(df_optimal['sharpen_strength'], bins=len(SHARPEN_STRENGTH), color='#fab1a0', edgecolor='black')\n",
    "axes[1, 2].set_title('Optimal Sharpen Strength', fontweight='bold')\n",
    "axes[1, 2].set_xlabel('Strength')\n",
    "axes[1, 2].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('âœ… Parameter distribution analysis complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb832972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze most common optimal settings\n",
    "print('ðŸŽ¯ Most Common Optimal Settings:')\n",
    "print('='*70)\n",
    "print()\n",
    "print(f\"Color correction used: {df_optimal['apply_color_correction'].sum()} / {len(df_optimal)} images ({df_optimal['apply_color_correction'].sum()/len(df_optimal)*100:.1f}%)\")\n",
    "print()\n",
    "print('Most common sharpen_sigma values:')\n",
    "print(df_optimal['sharpen_sigma'].value_counts().head())\n",
    "print()\n",
    "print('Most common sharpen_strength values:')\n",
    "print(df_optimal['sharpen_strength'].value_counts().head())\n",
    "print()\n",
    "print('Average PSNR improvement:', df_optimal['psnr'].mean(), 'dB')\n",
    "print('Average SSIM improvement:', df_optimal['ssim'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611df57a",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Step 6: Save Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2b6be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV for regression training\n",
    "output_path = '../data/processed/regression_training_data.csv'\n",
    "df_optimal.to_csv(output_path, index=False)\n",
    "\n",
    "print('ðŸ’¾ Training Dataset Saved!')\n",
    "print('='*70)\n",
    "print(f'File: {output_path}')\n",
    "print(f'Samples: {len(df_optimal)}')\n",
    "print(f'Features: {len([col for col in df_optimal.columns if col in feature_names])}')\n",
    "print(f'Target variables: apply_color_correction, sharpen_sigma, sharpen_strength')\n",
    "print()\n",
    "print('âœ… Ready for regression model training!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb716dab",
   "metadata": {},
   "source": [
    "## ðŸŽ¨ Step 7: Visualize Sample Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95aa443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show before/after examples with optimal parameters\n",
    "n_examples = 3\n",
    "sample_results = df_optimal.sample(min(n_examples, len(df_optimal)))\n",
    "\n",
    "fig, axes = plt.subplots(n_examples, 3, figsize=(15, 5*n_examples))\n",
    "if n_examples == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for idx, (_, row) in enumerate(sample_results.iterrows()):\n",
    "    filename = row['filename']\n",
    "    \n",
    "    # Load images\n",
    "    damaged_path = os.path.join(damaged_dir, filename)\n",
    "    undamaged_path = os.path.join(undamaged_dir, filename)\n",
    "    \n",
    "    damaged = cv2.imread(damaged_path)\n",
    "    undamaged = cv2.imread(undamaged_path)\n",
    "    \n",
    "    # Apply optimal restoration\n",
    "    if row['apply_color_correction'] == 1:\n",
    "        restored = restore_image_optimized(\n",
    "            damaged.copy(),\n",
    "            color_method=row['color_method'],\n",
    "            sharpen_sigma=row['sharpen_sigma'],\n",
    "            sharpen_strength=row['sharpen_strength']\n",
    "        )\n",
    "    else:\n",
    "        from src.basics.advanced_restoration import unsharp_mask\n",
    "        restored = unsharp_mask(\n",
    "            damaged.copy(),\n",
    "            sigma=row['sharpen_sigma'],\n",
    "            strength=row['sharpen_strength']\n",
    "        )\n",
    "    \n",
    "    # Convert BGR to RGB for display\n",
    "    damaged = cv2.cvtColor(damaged, cv2.COLOR_BGR2RGB)\n",
    "    restored = cv2.cvtColor(restored, cv2.COLOR_BGR2RGB)\n",
    "    undamaged = cv2.cvtColor(undamaged, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Display\n",
    "    axes[idx, 0].imshow(damaged)\n",
    "    axes[idx, 0].set_title('Damaged', fontweight='bold')\n",
    "    axes[idx, 0].axis('off')\n",
    "    \n",
    "    axes[idx, 1].imshow(restored)\n",
    "    axes[idx, 1].set_title(f'Restored\\nPSNR: {row[\"psnr\"]:.2f} dB, SSIM: {row[\"ssim\"]:.3f}', fontweight='bold')\n",
    "    axes[idx, 1].axis('off')\n",
    "    \n",
    "    axes[idx, 2].imshow(undamaged)\n",
    "    axes[idx, 2].set_title('Ground Truth', fontweight='bold')\n",
    "    axes[idx, 2].axis('off')\n",
    "    \n",
    "    # Add parameter info\n",
    "    param_text = f\"Color: {'Yes' if row['apply_color_correction'] == 1 else 'No'}\\n\"\n",
    "    param_text += f\"Sigma: {row['sharpen_sigma']}, Strength: {row['sharpen_strength']}\"\n",
    "    axes[idx, 1].text(0.5, -0.1, param_text, ha='center', transform=axes[idx, 1].transAxes, fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('âœ… Visual comparison complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da249bf0",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Summary\n",
    "\n",
    "### âœ… What We Accomplished:\n",
    "1. Loaded paired damaged/undamaged images\n",
    "2. Tested multiple restoration parameter combinations\n",
    "3. Found optimal parameters that maximize similarity to ground truth\n",
    "4. Extracted FFT features from damaged images\n",
    "5. Created training dataset: **[14 features] â†’ [optimal parameters]**\n",
    "\n",
    "### ðŸ“Š Dataset Created:\n",
    "- **Input**: 14 FFT features (damage characteristics)\n",
    "- **Output**: 3 optimal parameters (apply_color_correction, sharpen_sigma, sharpen_strength)\n",
    "- **Quality**: Measured by PSNR and SSIM against ground truth\n",
    "\n",
    "### ðŸš€ Next Steps:\n",
    "1. **Train regression model** in next notebook (`4_train_regression_model.ipynb`)\n",
    "2. **Use cross-validation** to ensure model generalizes well\n",
    "3. **Test on new images** and validate restoration quality\n",
    "4. **Deploy smart restoration** system\n",
    "\n",
    "### ðŸ’¡ Key Insights:\n",
    "- We now have **optimal restoration recipes** for each image\n",
    "- Model will learn to predict these recipes from damage features\n",
    "- This ensures we **never over-restore** (trained on what actually works!)\n",
    "\n",
    "**Ready to train the regression model!** ðŸ¤–âœ¨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
