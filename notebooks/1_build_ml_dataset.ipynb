{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a705f3a2",
   "metadata": {},
   "source": [
    "# Step 1: Build ML Dataset\n",
    "\n",
    "This notebook extracts FFT features from all images and creates a CSV dataset for machine learning.\n",
    "\n",
    "## What We'll Do:\n",
    "1. Load all damaged and undamaged images\n",
    "2. Extract 12 FFT features from each image\n",
    "3. Label them (damaged=1, undamaged=0)\n",
    "4. Save to CSV file\n",
    "\n",
    "## Why These Features?\n",
    "- **Statistical features (mean, std, skewness, kurtosis)**: Capture overall distribution\n",
    "- **Frequency bands (low, high, ratio)**: Identify noise vs content\n",
    "- **Radial profile**: Track how frequencies change from center to edge\n",
    "\n",
    "**Damaged images** typically have:\n",
    "- Higher high-frequency energy (scratches, noise)\n",
    "- Higher energy ratio (more noise relative to signal)\n",
    "- Irregular radial profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa64663",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0749aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Imports successful!\n",
      "Project root: d:\\R&D Project\\image_processing\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "# Import our feature extractor\n",
    "from src.ml.feature_extractor import extract_ml_features\n",
    "\n",
    "print(\"âœ“ Imports successful!\")\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6490f335",
   "metadata": {},
   "source": [
    "## Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e3378f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Damaged directory exists: True\n",
      "Undamaged directory exists: True\n",
      "\n",
      "Found 114 damaged images\n",
      "Found 114 undamaged images\n",
      "Total: 228 images\n"
     ]
    }
   ],
   "source": [
    "# Dataset paths\n",
    "data_path = os.path.join(project_root, \"data/raw/AI_for_Art_Restoration_2/paired_dataset_art\")\n",
    "damaged_dir = os.path.join(data_path, \"damaged\")\n",
    "undamaged_dir = os.path.join(data_path, \"undamaged\")\n",
    "\n",
    "# Output path\n",
    "output_dir = os.path.join(project_root, \"data/processed\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_csv = os.path.join(output_dir, \"fft_features.csv\")\n",
    "\n",
    "# Check if directories exist\n",
    "print(f\"Damaged directory exists: {os.path.exists(damaged_dir)}\")\n",
    "print(f\"Undamaged directory exists: {os.path.exists(undamaged_dir)}\")\n",
    "\n",
    "# Count files\n",
    "damaged_files = [f for f in os.listdir(damaged_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "undamaged_files = [f for f in os.listdir(undamaged_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "print(f\"\\nFound {len(damaged_files)} damaged images\")\n",
    "print(f\"Found {len(undamaged_files)} undamaged images\")\n",
    "print(f\"Total: {len(damaged_files) + len(undamaged_files)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9fd873",
   "metadata": {},
   "source": [
    "## Extract Features from All Images\n",
    "\n",
    "This will take a few minutes depending on how many images you have.\n",
    "\n",
    "**What's happening:**\n",
    "- Loop through each image\n",
    "- Apply FFT transform\n",
    "- Extract 12 features\n",
    "- Store in list with label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab991c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store features and labels\n",
    "all_features = []\n",
    "all_labels = []\n",
    "all_filenames = []\n",
    "feature_names = None\n",
    "\n",
    "print(\"Processing damaged images...\")\n",
    "for filename in tqdm(damaged_files):\n",
    "    try:\n",
    "        path = os.path.join(damaged_dir, filename)\n",
    "        features, names = extract_ml_features(path)\n",
    "        \n",
    "        all_features.append(features)\n",
    "        all_labels.append(1)  # 1 = damaged\n",
    "        all_filenames.append(filename)\n",
    "        \n",
    "        if feature_names is None:\n",
    "            feature_names = names\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "print(\"\\nProcessing undamaged images...\")\n",
    "for filename in tqdm(undamaged_files):\n",
    "    try:\n",
    "        path = os.path.join(undamaged_dir, filename)\n",
    "        features, names = extract_ml_features(path)\n",
    "        \n",
    "        all_features.append(features)\n",
    "        all_labels.append(0)  # 0 = undamaged\n",
    "        all_filenames.append(filename)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "print(f\"\\nâœ“ Successfully processed {len(all_features)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4fbea1",
   "metadata": {},
   "source": [
    "## Create DataFrame and Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da97d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(all_features, columns=feature_names)\n",
    "df['label'] = all_labels\n",
    "df['filename'] = all_filenames\n",
    "\n",
    "# Reorder columns (put filename and label first)\n",
    "cols = ['filename', 'label'] + feature_names\n",
    "df = df[cols]\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"âœ“ Saved dataset to: {output_csv}\")\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"Features: {len(feature_names)}\")\n",
    "print(f\"Samples: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f9c0fc",
   "metadata": {},
   "source": [
    "## Preview the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48b143e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first few rows\n",
    "print(\"First 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "# Show label distribution\n",
    "print(\"\\nLabel distribution:\")\n",
    "print(df['label'].value_counts())\n",
    "print(f\"\\n0 = Undamaged: {(df['label']==0).sum()} images\")\n",
    "print(f\"1 = Damaged: {(df['label']==1).sum()} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5800cfdc",
   "metadata": {},
   "source": [
    "## Basic Statistics\n",
    "\n",
    "Let's see if damaged and undamaged images have different feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b670ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare damaged vs undamaged\n",
    "damaged_df = df[df['label'] == 1]\n",
    "undamaged_df = df[df['label'] == 0]\n",
    "\n",
    "print(\"Feature Comparison (Damaged vs Undamaged)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Feature':<20} {'Damaged (mean)':>15} {'Undamaged (mean)':>18} {'Difference':>12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for feature in feature_names:\n",
    "    damaged_mean = damaged_df[feature].mean()\n",
    "    undamaged_mean = undamaged_df[feature].mean()\n",
    "    diff = damaged_mean - undamaged_mean\n",
    "    \n",
    "    print(f\"{feature:<20} {damaged_mean:>15.4f} {undamaged_mean:>18.4f} {diff:>12.4f}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Key Observations:\")\n",
    "print(\"   Look for features with large differences - these are most useful for classification!\")\n",
    "print(\"   Typically:\")\n",
    "print(\"   - high_freq_energy: Higher for damaged (scratches/noise)\")\n",
    "print(\"   - energy_ratio: Higher for damaged (more noise relative to signal)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ea8829",
   "metadata": {},
   "source": [
    "## Visualize Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd5c935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot distributions of key features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Feature Distributions: Damaged vs Undamaged', fontsize=16)\n",
    "\n",
    "key_features = ['high_freq_energy', 'energy_ratio', 'low_freq_energy', 'std_dev']\n",
    "\n",
    "for idx, feature in enumerate(key_features):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    \n",
    "    ax.hist(damaged_df[feature], bins=30, alpha=0.5, label='Damaged', color='red')\n",
    "    ax.hist(undamaged_df[feature], bins=30, alpha=0.5, label='Undamaged', color='blue')\n",
    "    \n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title(f'{feature} Distribution')\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Interpretation:\")\n",
    "print(\"   - If histograms are well-separated â†’ feature is good for classification\")\n",
    "print(\"   - If histograms overlap heavily â†’ feature is less useful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a02507",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "âœ… **What We Accomplished:**\n",
    "1. Extracted 12 FFT features from all images\n",
    "2. Created labeled dataset (damaged=1, undamaged=0)\n",
    "3. Saved to CSV for ML training\n",
    "4. Visualized feature distributions\n",
    "\n",
    "ðŸ“Š **Dataset Ready!**\n",
    "- File: `data/processed/fft_features.csv`\n",
    "- Features: 12 per image\n",
    "- Labels: Binary (damaged/undamaged)\n",
    "\n",
    "ðŸŽ¯ **Next Step:**\n",
    "Open notebook `2_train_classifier.ipynb` to train a machine learning model!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
