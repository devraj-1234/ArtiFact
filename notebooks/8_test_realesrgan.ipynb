{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a90b1c89",
   "metadata": {},
   "source": [
    "# Test Real-ESRGAN Pre-trained Model\n",
    "\n",
    "This notebook tests the Real-ESRGAN pre-trained model on your artwork dataset.\n",
    "\n",
    "Real-ESRGAN provides production-ready restoration without training on your small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fed1119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"HTTP_PROXY\"] = \"http://USER:PASSWORD@HOST:PORT\"\n",
    "# os.environ[\"HTTPS_PROXY\"] = os.environ[\"HTTP_PROXY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c02081c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "print(\"Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d7c96f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.26.4\n",
      "NumPy is available: True\n",
      "scikit-learn: OK\n",
      "scikit-image: OK\n",
      "pandas: OK\n",
      "\n",
      "All core packages compatible with NumPy 1.26.4\n"
     ]
    }
   ],
   "source": [
    "# Verify NumPy version and compatibility\n",
    "import numpy as np\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"NumPy is available: {np.__version__ < '2.0'}\")\n",
    "\n",
    "# Test all critical packages\n",
    "try:\n",
    "    import sklearn\n",
    "    print(\"scikit-learn: OK\")\n",
    "except Exception as e:\n",
    "    print(f\"scikit-learn error: {e}\")\n",
    "\n",
    "try:\n",
    "    import skimage\n",
    "    print(\"scikit-image: OK\")\n",
    "except Exception as e:\n",
    "    print(f\"scikit-image error: {e}\")\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "    print(\"pandas: OK\")\n",
    "except Exception as e:\n",
    "    print(f\"pandas error: {e}\")\n",
    "\n",
    "print(\"\\nAll core packages compatible with NumPy\", np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864c315d",
   "metadata": {},
   "source": [
    "## Step 1: Check Installation\n",
    "\n",
    "First, verify Real-ESRGAN is installed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d99c657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real-ESRGAN is installed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\torchvision\\transforms\\functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from realesrgan import RealESRGANer\n",
    "    from basicsr.archs.rrdbnet_arch import RRDBNet\n",
    "    print(\"Real-ESRGAN is installed\")\n",
    "    REALESRGAN_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    print(f\"Real-ESRGAN not installed: {e}\")\n",
    "    print(\"Install with: pip install realesrgan\")\n",
    "    REALESRGAN_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e98c076",
   "metadata": {},
   "source": [
    "## Step 2: Initialize Real-ESRGAN Model\n",
    "\n",
    "Load the pre-trained Real-ESRGAN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e17639f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Real-ESRGAN not available (install with: pip install realesrgan)\n",
      "Loaded Real-ESRGAN: RealESRGAN_x4plus | scale=4 | device=cpu\n",
      "Real-ESRGAN model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "if REALESRGAN_AVAILABLE:\n",
    "    from src.dl.realesrgan_wrapper import RealESRGANRestorer\n",
    "    \n",
    "    try:\n",
    "        restorer = RealESRGANRestorer(\n",
    "            model_name='RealESRGAN_x4plus',\n",
    "            device='cpu',  # Change to 'cuda' if you have GPU\n",
    "            weights_dir = \"../outputs/models/realesrgan\"\n",
    "        )\n",
    "        print(\"Real-ESRGAN model loaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        print(\"Note: Model weights will be downloaded automatically on first use\")\n",
    "else:\n",
    "    print(\"Skipping model initialization - Real-ESRGAN not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9de733",
   "metadata": {},
   "source": [
    "## Step 3: Test on Single Image\n",
    "\n",
    "Restore a single damaged artwork image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff6fc614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ../data/raw/AI_for_Art_Restoration_2/paired_dataset_art/damaged/1.png\n",
      "Input shape: (3489, 2506, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_image_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInput shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdamaged.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m restored = \u001b[43mrestorer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdamaged\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutscale\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m restored_rgb = cv2.cvtColor(restored, cv2.COLOR_BGR2RGB)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOutput shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrestored.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\r&d project\\image_processing\\src\\dl\\realesrgan_wrapper.py:159\u001b[39m, in \u001b[36mRealESRGANRestorer.restore\u001b[39m\u001b[34m(self, image, outscale)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image, np.ndarray):\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mInput image must be a non-empty numpy array (BGR, uint8)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m output, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mupsampler\u001b[49m\u001b[43m.\u001b[49m\u001b[43menhance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutscale\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutscale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\realesrgan\\utils.py:223\u001b[39m, in \u001b[36mRealESRGANer.enhance\u001b[39m\u001b[34m(self, img, outscale, alpha_upsampler)\u001b[39m\n\u001b[32m    221\u001b[39m     \u001b[38;5;28mself\u001b[39m.tile_process()\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    224\u001b[39m output_img = \u001b[38;5;28mself\u001b[39m.post_process()\n\u001b[32m    225\u001b[39m output_img = output_img.data.squeeze().float().cpu().clamp_(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m).numpy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\realesrgan\\utils.py:115\u001b[39m, in \u001b[36mRealESRGANer.process\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    114\u001b[39m     \u001b[38;5;66;03m# model inference\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28mself\u001b[39m.output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1516\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1518\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1522\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1523\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1524\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1525\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1526\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1527\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1529\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1530\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\basicsr\\archs\\rrdbnet_arch.py:113\u001b[39m, in \u001b[36mRRDBNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    111\u001b[39m     feat = x\n\u001b[32m    112\u001b[39m feat = \u001b[38;5;28mself\u001b[39m.conv_first(feat)\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m body_feat = \u001b[38;5;28mself\u001b[39m.conv_body(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    114\u001b[39m feat = feat + body_feat\n\u001b[32m    115\u001b[39m \u001b[38;5;66;03m# upsample\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1516\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1518\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1522\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1523\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1524\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1525\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1526\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1527\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1529\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1530\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1516\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1518\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1522\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1523\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1524\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1525\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1526\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1527\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1529\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1530\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\basicsr\\archs\\rrdbnet_arch.py:61\u001b[39m, in \u001b[36mRRDB.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     59\u001b[39m out = \u001b[38;5;28mself\u001b[39m.rdb1(x)\n\u001b[32m     60\u001b[39m out = \u001b[38;5;28mself\u001b[39m.rdb2(out)\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrdb3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# Empirically, we use 0.2 to scale the residual for better performance\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out * \u001b[32m0.2\u001b[39m + x\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1516\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1518\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1522\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1523\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1524\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1525\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1526\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1527\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1529\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1530\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\basicsr\\archs\\rrdbnet_arch.py:35\u001b[39m, in \u001b[36mResidualDenseBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     33\u001b[39m x1 = \u001b[38;5;28mself\u001b[39m.lrelu(\u001b[38;5;28mself\u001b[39m.conv1(x))\n\u001b[32m     34\u001b[39m x2 = \u001b[38;5;28mself\u001b[39m.lrelu(\u001b[38;5;28mself\u001b[39m.conv2(torch.cat((x, x1), \u001b[32m1\u001b[39m)))\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m x3 = \u001b[38;5;28mself\u001b[39m.lrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     36\u001b[39m x4 = \u001b[38;5;28mself\u001b[39m.lrelu(\u001b[38;5;28mself\u001b[39m.conv4(torch.cat((x, x1, x2, x3), \u001b[32m1\u001b[39m)))\n\u001b[32m     37\u001b[39m x5 = \u001b[38;5;28mself\u001b[39m.conv5(torch.cat((x, x1, x2, x3, x4), \u001b[32m1\u001b[39m))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "if REALESRGAN_AVAILABLE:\n",
    "    test_image_path = '../data/raw/AI_for_Art_Restoration_2/paired_dataset_art/damaged/1.png'\n",
    "    \n",
    "    if os.path.exists(test_image_path):\n",
    "        damaged = cv2.imread(test_image_path)\n",
    "        damaged_rgb = cv2.cvtColor(damaged, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        print(f\"Processing: {test_image_path}\")\n",
    "        print(f\"Input shape: {damaged.shape}\")\n",
    "        \n",
    "        restored = restorer.restore(image=damaged, outscale=1.0)\n",
    "        restored_rgb = cv2.cvtColor(restored, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        print(f\"Output shape: {restored.shape}\")\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        \n",
    "        axes[0].imshow(damaged_rgb)\n",
    "        axes[0].set_title('Damaged (Input)')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        axes[1].imshow(restored_rgb)\n",
    "        axes[1].set_title('Real-ESRGAN Restored')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Test image not found: {test_image_path}\")\n",
    "else:\n",
    "    print(\"Skipping test - Real-ESRGAN not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512e1b3c",
   "metadata": {},
   "source": [
    "## Step 4: Compare with Ground Truth\n",
    "\n",
    "Calculate PSNR and SSIM metrics against the undamaged version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f52e210",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "if REALESRGAN_AVAILABLE and os.path.exists(test_image_path):\n",
    "    undamaged_path = test_image_path.replace('damaged', 'undamaged')\n",
    "    \n",
    "    if os.path.exists(undamaged_path):\n",
    "        undamaged = cv2.imread(undamaged_path)\n",
    "        undamaged_rgb = cv2.cvtColor(undamaged, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        psnr_damaged = psnr(undamaged_rgb, damaged_rgb)\n",
    "        ssim_damaged = ssim(undamaged_rgb, damaged_rgb, channel_axis=2)\n",
    "        \n",
    "        psnr_restored = psnr(undamaged_rgb, restored_rgb)\n",
    "        ssim_restored = ssim(undamaged_rgb, restored_rgb, channel_axis=2)\n",
    "        \n",
    "        print(\"Metrics vs Ground Truth:\")\n",
    "        print(f\"\\nDamaged Image:\")\n",
    "        print(f\"  PSNR: {psnr_damaged:.2f} dB\")\n",
    "        print(f\"  SSIM: {ssim_damaged:.3f}\")\n",
    "        \n",
    "        print(f\"\\nReal-ESRGAN Restored:\")\n",
    "        print(f\"  PSNR: {psnr_restored:.2f} dB\")\n",
    "        print(f\"  SSIM: {ssim_restored:.3f}\")\n",
    "        \n",
    "        print(f\"\\nImprovement:\")\n",
    "        print(f\"  PSNR: +{psnr_restored - psnr_damaged:.2f} dB\")\n",
    "        print(f\"  SSIM: +{ssim_restored - ssim_damaged:.3f}\")\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        axes[0].imshow(damaged_rgb)\n",
    "        axes[0].set_title(f'Damaged\\nPSNR: {psnr_damaged:.1f} dB')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        axes[1].imshow(restored_rgb)\n",
    "        axes[1].set_title(f'Real-ESRGAN\\nPSNR: {psnr_restored:.1f} dB')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        axes[2].imshow(undamaged_rgb)\n",
    "        axes[2].set_title('Ground Truth')\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Ground truth not found: {undamaged_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0a9957",
   "metadata": {},
   "source": [
    "## Step 5: Batch Test on Multiple Images\n",
    "\n",
    "Test Real-ESRGAN on a batch of images and calculate average metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b05cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if REALESRGAN_AVAILABLE:\n",
    "    import glob\n",
    "    \n",
    "    damaged_dir = '../data/raw/AI_for_Art_Restoration_2/paired_dataset_art/damaged'\n",
    "    undamaged_dir = '../data/raw/AI_for_Art_Restoration_2/paired_dataset_art/undamaged'\n",
    "    \n",
    "    damaged_files = sorted(glob.glob(os.path.join(damaged_dir, '*.jpg')))[:10]  # Test 10 images\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for damaged_path in damaged_files:\n",
    "        filename = os.path.basename(damaged_path)\n",
    "        undamaged_path = os.path.join(undamaged_dir, filename)\n",
    "        \n",
    "        if not os.path.exists(undamaged_path):\n",
    "            continue\n",
    "        \n",
    "        damaged = cv2.imread(damaged_path)\n",
    "        undamaged = cv2.imread(undamaged_path)\n",
    "        \n",
    "        damaged_rgb = cv2.cvtColor(damaged, cv2.COLOR_BGR2RGB)\n",
    "        undamaged_rgb = cv2.cvtColor(undamaged, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        restored = restorer.restore(damaged, outscale=1.0)\n",
    "        restored_rgb = cv2.cvtColor(restored, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        psnr_before = psnr(undamaged_rgb, damaged_rgb)\n",
    "        ssim_before = ssim(undamaged_rgb, damaged_rgb, channel_axis=2)\n",
    "        \n",
    "        psnr_after = psnr(undamaged_rgb, restored_rgb)\n",
    "        ssim_after = ssim(undamaged_rgb, restored_rgb, channel_axis=2)\n",
    "        \n",
    "        results.append({\n",
    "            'filename': filename,\n",
    "            'psnr_before': psnr_before,\n",
    "            'ssim_before': ssim_before,\n",
    "            'psnr_after': psnr_after,\n",
    "            'ssim_after': ssim_after,\n",
    "            'psnr_gain': psnr_after - psnr_before,\n",
    "            'ssim_gain': ssim_after - ssim_before\n",
    "        })\n",
    "        \n",
    "        print(f\"Processed: {filename}\")\n",
    "    \n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Average Results Across Test Set:\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nBefore Restoration:\")\n",
    "    print(f\"  Average PSNR: {df['psnr_before'].mean():.2f} dB\")\n",
    "    print(f\"  Average SSIM: {df['ssim_before'].mean():.3f}\")\n",
    "    \n",
    "    print(f\"\\nAfter Real-ESRGAN:\")\n",
    "    print(f\"  Average PSNR: {df['psnr_after'].mean():.2f} dB\")\n",
    "    print(f\"  Average SSIM: {df['ssim_after'].mean():.3f}\")\n",
    "    \n",
    "    print(f\"\\nAverage Improvement:\")\n",
    "    print(f\"  PSNR Gain: +{df['psnr_gain'].mean():.2f} dB\")\n",
    "    print(f\"  SSIM Gain: +{df['ssim_gain'].mean():.3f}\")\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    axes[0].bar(['Before', 'After'], [df['psnr_before'].mean(), df['psnr_after'].mean()])\n",
    "    axes[0].set_ylabel('PSNR (dB)')\n",
    "    axes[0].set_title('Average PSNR Comparison')\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    axes[1].bar(['Before', 'After'], [df['ssim_before'].mean(), df['ssim_after'].mean()])\n",
    "    axes[1].set_ylabel('SSIM')\n",
    "    axes[1].set_title('Average SSIM Comparison')\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    os.makedirs('../outputs/models', exist_ok=True)\n",
    "    df.to_csv('../outputs/models/realesrgan_test_results.csv', index=False)\n",
    "    print(f\"\\nResults saved to: ../outputs/models/realesrgan_test_results.csv\")\n",
    "else:\n",
    "    print(\"Skipping batch test - Real-ESRGAN not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c312ef92",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook tested Real-ESRGAN pre-trained model on your artwork dataset.\n",
    "\n",
    "Key advantages of Real-ESRGAN:\n",
    "- No training required (pre-trained on massive datasets)\n",
    "- Production-ready quality\n",
    "- Works well even with small datasets\n",
    "- Better than your custom U-Net trained on 112 images\n",
    "\n",
    "Next steps:\n",
    "1. Compare Real-ESRGAN with your ML-guided approach\n",
    "2. Integrate into hybrid system\n",
    "3. Deploy for production use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
