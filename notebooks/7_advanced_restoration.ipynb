{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fc3aca8",
   "metadata": {},
   "source": [
    "# 🎨 Advanced Art Restoration: Handling Tears, Holes & Missing Parts\n",
    "\n",
    "This notebook demonstrates advanced restoration techniques that can handle:\n",
    "- **Structural damage**: tears, cracks, holes\n",
    "- **Missing parts**: large missing regions\n",
    "- **Quality degradation**: color, sharpness, noise\n",
    "\n",
    "The system combines:\n",
    "1. **Computer vision** for damage detection\n",
    "2. **Deep learning inpainting** for structural repair\n",
    "3. **Hybrid ML+DL** for quality restoration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7753257b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Add the project root to the Python path\u001b[39;00m\n\u001b[32m     11\u001b[39m project_root = os.path.abspath(os.path.join(os.getcwd(), \u001b[33m'\u001b[39m\u001b[33m..\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\tensorflow\\__init__.py:468\u001b[39m\n\u001b[32m    466\u001b[39m     importlib.import_module(\u001b[33m\"\u001b[39m\u001b[33mtf_keras.src.optimizers\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    467\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m468\u001b[39m     \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mkeras.src.optimizers\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[32m    470\u001b[39m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\importlib\\__init__.py:126\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m    124\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    125\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\keras\\__init__.py:7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _tf_keras \u001b[38;5;28;01mas\u001b[39;00m _tf_keras\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m activations \u001b[38;5;28;01mas\u001b[39;00m activations\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m applications \u001b[38;5;28;01mas\u001b[39;00m applications\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\keras\\_tf_keras\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tf_keras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\keras\\_tf_keras\\keras\\__init__.py:28\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils \u001b[38;5;28;01mas\u001b[39;00m utils\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m visualization \u001b[38;5;28;01mas\u001b[39;00m visualization\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m wrappers \u001b[38;5;28;01mas\u001b[39;00m wrappers\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tf_keras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backend \u001b[38;5;28;01mas\u001b[39;00m backend\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tf_keras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers \u001b[38;5;28;01mas\u001b[39;00m layers\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\keras\\wrappers\\__init__.py:7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwrappers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msklearn_wrapper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      8\u001b[39m     SKLearnClassifier \u001b[38;5;28;01mas\u001b[39;00m SKLearnClassifier,\n\u001b[32m      9\u001b[39m )\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwrappers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msklearn_wrapper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     SKLearnRegressor \u001b[38;5;28;01mas\u001b[39;00m SKLearnRegressor,\n\u001b[32m     12\u001b[39m )\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwrappers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msklearn_wrapper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     14\u001b[39m     SKLearnTransformer \u001b[38;5;28;01mas\u001b[39;00m SKLearnTransformer,\n\u001b[32m     15\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\keras\\src\\wrappers\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwrappers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msklearn_wrapper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SKLearnClassifier\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwrappers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msklearn_wrapper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SKLearnRegressor\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwrappers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msklearn_wrapper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SKLearnTransformer\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\keras\\src\\wrappers\\sklearn_wrapper.py:8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcloning\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone_model\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwrappers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfixes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _routing_enabled\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwrappers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfixes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _validate_data\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwrappers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfixes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m type_of_target\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\keras\\src\\wrappers\\fixes.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m      4\u001b[39m     sklearn = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\sklearn\\__init__.py:73\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# `_distributor_init` allows distributors to run custom init code.\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# For instance, for the Windows wheel, this is used to pre-load the\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# vcomp shared library runtime for OpenMP embedded in the sklearn/.libs\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401 E402\u001b[39;00m\n\u001b[32m     70\u001b[39m     __check_build,\n\u001b[32m     71\u001b[39m     _distributor_init,\n\u001b[32m     72\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_show_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[32m     76\u001b[39m _submodules = [\n\u001b[32m     77\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcalibration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     78\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcluster\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    114\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcompose\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    115\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\sklearn\\base.py:19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_metadata_requests\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_missing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_scalar_nan\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_param_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\sklearn\\utils\\__init__.py:9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m metadata_routing\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_bunch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_chunking\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gen_batches, gen_even_slices\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Make _safe_indexing importable from here for backward compat as this particular\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# helper is considered semi-private and typically very useful for third-party\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# libraries that want to comply with scikit-learn's estimator API. In particular,\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# _safe_indexing was included in our public API documentation despite the leading\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# `_` in its name.\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_indexing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     17\u001b[39m     _safe_indexing,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     18\u001b[39m     resample,\n\u001b[32m     19\u001b[39m     shuffle,\n\u001b[32m     20\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\sklearn\\utils\\_chunking.py:11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_param_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchunk_generator\u001b[39m(gen, chunksize):\n\u001b[32m     15\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[33;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mInvalidParameterError\u001b[39;00m(\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m     21\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Custom exception to be raised when the parameter of a class/method/function\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[33;03m    does not have a valid type or value.\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:21\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_config \u001b[38;5;28;01mas\u001b[39;00m _get_config\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataConversionWarning, NotFittedError, PositiveSpectrumWarning\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_array_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _asarray_with_order, _is_numpy_namespace, get_namespace\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdeprecation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _deprecate_force_all_finite\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfixes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ComplexWarning, _preserve_dia_indices_dtype\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexternals\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m array_api_extra \u001b[38;5;28;01mas\u001b[39;00m xpx\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexternals\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marray_api_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m numpy \u001b[38;5;28;01mas\u001b[39;00m np_compat\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfixes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse_version\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# TODO: complete __all__\u001b[39;00m\n\u001b[32m     23\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33mxpx\u001b[39m\u001b[33m\"\u001b[39m]  \u001b[38;5;66;03m# we import xpx here just to re-export it, need this to appease ruff\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\sklearn\\utils\\fixes.py:16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinalg\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m optimize\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\scipy\\stats\\__init__.py:630\u001b[39m\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_morestats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_multicomp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_binomtest\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m binomtest\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_binned_statistic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\scipy\\stats\\_multicomp.py:11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptimize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m minimize_scalar\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_common\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConfidenceInterval\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_qmc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_random_state\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_stats_py\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _var\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_util\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _transition_to_rng, DecimalNumber, SeedType\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\R&D Project\\image_processing\\venv\\Lib\\site-packages\\scipy\\stats\\_qmc.py:26\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstats\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_util\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m rng_integers, _rng_spawn, _transition_to_rng\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcsgraph\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m minimum_spanning_tree\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mspatial\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m distance, Voronoi\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mspecial\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gammainc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1176\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1147\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:690\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:936\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1032\u001b[39m, in \u001b[36mget_code\u001b[39m\u001b[34m(self, fullname)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1130\u001b[39m, in \u001b[36mget_data\u001b[39m\u001b[34m(self, path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "# Add the project root to the Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "\tsys.path.insert(0, project_root)\n",
    "\n",
    "\n",
    "from src.dl.advanced_restorer import AdvancedRestorer, StructuralDamageDetector, DeepInpainter\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be213cce",
   "metadata": {},
   "source": [
    "## 🔍 Step 1: Damage Detection Analysis\n",
    "\n",
    "Let's analyze what types of damage our current system can and cannot handle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baced686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize damage detector\n",
    "detector = StructuralDamageDetector()\n",
    "\n",
    "# Test on a sample image\n",
    "test_image_path = '../data/raw/AI_for_Art_Restoration_2/paired_dataset_art/damaged/image_1.jpg'\n",
    "\n",
    "if os.path.exists(test_image_path):\n",
    "    image = cv2.imread(test_image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Detect all damage types\n",
    "    damage_info = detector.detect_all_damage(image)\n",
    "    \n",
    "    # Visualize results\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0, 0].imshow(image_rgb)\n",
    "    axes[0, 0].set_title('Original Damaged Image')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Crack detection\n",
    "    axes[0, 1].imshow(damage_info['crack_mask'], cmap='gray')\n",
    "    axes[0, 1].set_title(f'Detected Cracks ({len(damage_info[\"cracks\"])} found)')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # Hole detection\n",
    "    axes[0, 2].imshow(damage_info['hole_mask'], cmap='gray')\n",
    "    axes[0, 2].set_title(f'Detected Holes ({len(damage_info[\"holes\"])} found)')\n",
    "    axes[0, 2].axis('off')\n",
    "    \n",
    "    # Combined damage mask\n",
    "    axes[1, 0].imshow(damage_info['combined_mask'], cmap='hot')\n",
    "    axes[1, 0].set_title(f'All Damage ({damage_info[\"damage_percentage\"]:.1f}% of image)')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    # Overlay damage on original\n",
    "    overlay = image_rgb.copy()\n",
    "    damage_overlay = np.stack([damage_info['combined_mask']] * 3, axis=-1)\n",
    "    overlay[damage_overlay > 0] = [255, 0, 0]  # Red overlay for damage\n",
    "    \n",
    "    axes[1, 1].imshow(cv2.addWeighted(image_rgb, 0.7, overlay, 0.3, 0))\n",
    "    axes[1, 1].set_title('Damage Overlay (Red = Detected)')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    # Damage statistics\n",
    "    stats_text = f\"\"\"Damage Analysis:\n",
    "• Total damaged area: {damage_info['damage_percentage']:.1f}%\n",
    "• Cracks/tears found: {len(damage_info['cracks'])}\n",
    "• Holes/missing parts: {len(damage_info['holes'])}\n",
    "• Structural damage: {'Yes' if damage_info['has_structural_damage'] else 'No'}\n",
    "\n",
    "Current hybrid system only handles:\n",
    "✓ Color correction\n",
    "✓ Sharpening\n",
    "✓ General enhancement\n",
    "\n",
    "Advanced system adds:\n",
    "✓ Tear/crack repair\n",
    "✓ Hole filling\n",
    "✓ Missing part reconstruction\"\"\"\n",
    "    \n",
    "    axes[1, 2].text(0.05, 0.95, stats_text, transform=axes[1, 2].transAxes, \n",
    "                    fontsize=10, verticalalignment='top', \n",
    "                    bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "    axes[1, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n📊 Damage Detection Results:\")\n",
    "    print(f\"Structural damage detected: {damage_info['has_structural_damage']}\")\n",
    "    if damage_info['has_structural_damage']:\n",
    "        print(f\"This image needs advanced restoration with inpainting!\")\n",
    "    else:\n",
    "        print(f\"This image can be handled by the current hybrid system.\")\n",
    "        \n",
    "else:\n",
    "    print(\"⚠️ Test image not found. Please check the path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778b5052",
   "metadata": {},
   "source": [
    "## 🧠 Step 2: Deep Learning Inpainting Model\n",
    "\n",
    "Let's create and test the inpainting component that can fill holes and repair tears:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ef292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize inpainter (will use traditional method if DL model not available)\n",
    "inpainter = DeepInpainter()\n",
    "\n",
    "print(\"🎯 Inpainting Model Status:\")\n",
    "if inpainter.model is not None:\n",
    "    print(\"✅ Deep learning model initialized\")\n",
    "    inpainter.model.summary()\n",
    "else:\n",
    "    print(\"⚠️ Using traditional OpenCV inpainting (faster but less sophisticated)\")\n",
    "    print(\"   For better results, train the deep learning model first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1740f6",
   "metadata": {},
   "source": [
    "## 🔧 Step 3: Test Inpainting on Simulated Damage\n",
    "\n",
    "Let's create some artificial damage to test our inpainting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9e46bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(test_image_path):\n",
    "    # Load a clean-ish image for testing\n",
    "    test_img = cv2.imread(test_image_path)\n",
    "    test_img_rgb = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Create artificial damage for testing\n",
    "    h, w = test_img.shape[:2]\n",
    "    artificial_mask = np.zeros((h, w), dtype=np.uint8)\n",
    "    \n",
    "    # Add some artificial tears (lines)\n",
    "    cv2.line(artificial_mask, (w//4, h//4), (3*w//4, 3*h//4), 255, 15)\n",
    "    cv2.line(artificial_mask, (w//2, 0), (w//2, h//3), 255, 8)\n",
    "    \n",
    "    # Add some holes (circles)\n",
    "    cv2.circle(artificial_mask, (w//6, h//3), 25, 255, -1)\n",
    "    cv2.circle(artificial_mask, (5*w//6, 2*h//3), 20, 255, -1)\n",
    "    \n",
    "    # Add rectangular missing part\n",
    "    cv2.rectangle(artificial_mask, (w//3, h//6), (2*w//3, h//3), 255, -1)\n",
    "    \n",
    "    # Create damaged version\n",
    "    damaged_img = test_img.copy()\n",
    "    damaged_img[artificial_mask > 0] = [0, 0, 0]  # Black damage\n",
    "    \n",
    "    # Test inpainting\n",
    "    print(\"🔧 Testing inpainting on artificial damage...\")\n",
    "    inpainted = inpainter.inpaint(damaged_img, artificial_mask)\n",
    "    \n",
    "    # Visualize results\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    axes[0, 0].imshow(test_img_rgb)\n",
    "    axes[0, 0].set_title('Original Image')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    axes[0, 1].imshow(cv2.cvtColor(damaged_img, cv2.COLOR_BGR2RGB))\n",
    "    axes[0, 1].set_title('Artificially Damaged')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    axes[1, 0].imshow(artificial_mask, cmap='gray')\n",
    "    axes[1, 0].set_title('Damage Mask')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    axes[1, 1].imshow(cv2.cvtColor(inpainted, cv2.COLOR_BGR2RGB))\n",
    "    axes[1, 1].set_title('Inpainted Result')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    # PSNR for inpainted regions\n",
    "    original_region = test_img_rgb[artificial_mask > 0]\n",
    "    inpainted_region = cv2.cvtColor(inpainted, cv2.COLOR_BGR2RGB)[artificial_mask > 0]\n",
    "    \n",
    "    if len(original_region) > 0:\n",
    "        mse = np.mean((original_region.astype(float) - inpainted_region.astype(float)) ** 2)\n",
    "        if mse > 0:\n",
    "            psnr = 20 * np.log10(255.0 / np.sqrt(mse))\n",
    "            print(f\"\\n📈 Inpainting Quality (damaged regions only):\")\n",
    "            print(f\"PSNR: {psnr:.2f} dB\")\n",
    "        \n",
    "    print(f\"✅ Inpainting test completed!\")\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ Test image not found for inpainting demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770e1a60",
   "metadata": {},
   "source": [
    "## 🚀 Step 4: Complete Advanced Restoration System\n",
    "\n",
    "Now let's test the full advanced restoration pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a437c6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize advanced restorer\n",
    "try:\n",
    "    advanced_restorer = AdvancedRestorer(\n",
    "        ml_model_path='../outputs/models/restoration_parameter_predictor.pkl',\n",
    "        ml_scaler_path='../outputs/models/parameter_feature_scaler.pkl',\n",
    "        use_dl=True  # Enable U-Net if available\n",
    "    )\n",
    "    print(\"✅ Advanced restoration system initialized!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Could not initialize full system: {e}\")\n",
    "    print(\"Make sure you've trained the ML models first (notebooks 1-4)\")\n",
    "    advanced_restorer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a33577",
   "metadata": {},
   "outputs": [],
   "source": [
    "if advanced_restorer and os.path.exists(test_image_path):\n",
    "    print(\"🎨 Running complete advanced restoration...\")\n",
    "    \n",
    "    # Run advanced restoration\n",
    "    restored, info = advanced_restorer.restore_advanced(\n",
    "        test_image_path,\n",
    "        output_path='../outputs/advanced_restoration_result.jpg',\n",
    "        strategy='auto'\n",
    "    )\n",
    "    \n",
    "    # Load original for comparison\n",
    "    original = cv2.imread(test_image_path)\n",
    "    original_rgb = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n",
    "    restored_rgb = cv2.cvtColor(restored, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Visualize results\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Original damaged\n",
    "    axes[0, 0].imshow(original_rgb)\n",
    "    axes[0, 0].set_title('Original Damaged Image')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Advanced restoration result\n",
    "    axes[0, 1].imshow(restored_rgb)\n",
    "    axes[0, 1].set_title('Advanced Restoration Result')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # Damage visualization\n",
    "    damage_viz = original_rgb.copy()\n",
    "    if info['structural_damage']['has_structural_damage']:\n",
    "        mask = info['structural_damage']['combined_mask']\n",
    "        damage_overlay = np.stack([mask] * 3, axis=-1)\n",
    "        damage_viz[damage_overlay > 0] = [255, 0, 0]\n",
    "    \n",
    "    axes[1, 0].imshow(cv2.addWeighted(original_rgb, 0.7, damage_viz, 0.3, 0))\n",
    "    axes[1, 0].set_title('Detected Damage (Red)')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    # Restoration info\n",
    "    info_text = f\"\"\"Advanced Restoration Report:\n",
    "\n",
    "🔍 Damage Analysis:\n",
    "• Structural damage: {'Yes' if info['has_structural_repair'] else 'No'}\n",
    "• Quality severity: {info['quality_analysis']['severity']}\n",
    "• Damage coverage: {info['structural_damage']['damage_percentage']:.1f}%\n",
    "\n",
    "🔧 Restoration Steps:\n",
    "{chr(10).join(f'• {step}' for step in info['restoration_steps'])}\n",
    "\n",
    "⚡ Method Used: {info['final_method']}\n",
    "\n",
    "🎯 Key Improvements:\n",
    "• Tears and cracks repaired\n",
    "• Missing parts reconstructed  \n",
    "• Color and sharpness enhanced\n",
    "• Combined ML + DL approach\n",
    "\n",
    "This advanced system can handle:\n",
    "✓ Complex structural damage\n",
    "✓ Multiple damage types\n",
    "✓ Quality + structural repair\"\"\"\n",
    "    \n",
    "    axes[1, 1].text(0.05, 0.95, info_text, transform=axes[1, 1].transAxes,\n",
    "                    fontsize=9, verticalalignment='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n🎉 Advanced restoration completed!\")\n",
    "    print(f\"Result saved to: ../outputs/advanced_restoration_result.jpg\")\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ Skipping advanced restoration demo (missing models or test image)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07e3b9c",
   "metadata": {},
   "source": [
    "## 📊 Step 5: Method Comparison\n",
    "\n",
    "Let's compare all restoration methods side by side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396cc8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if advanced_restorer and os.path.exists(test_image_path):\n",
    "    print(\"🔬 Comparing all restoration methods...\")\n",
    "    \n",
    "    # Compare all methods\n",
    "    comparison = advanced_restorer.compare_all_methods(test_image_path)\n",
    "    \n",
    "    # Create visualization\n",
    "    methods = ['original', 'classical', 'ml_guided', 'advanced']\n",
    "    titles = ['Original Damaged', 'Classical Only', 'ML-Guided', 'Advanced (ML+DL+Inpainting)']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (method, title) in enumerate(zip(methods, titles)):\n",
    "        if method in comparison:\n",
    "            img = comparison[method]\n",
    "            if len(img.shape) == 3:\n",
    "                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            else:\n",
    "                img_rgb = img\n",
    "            \n",
    "            axes[i].imshow(img_rgb)\n",
    "            axes[i].set_title(title, fontsize=12, fontweight='bold')\n",
    "            axes[i].axis('off')\n",
    "            \n",
    "            # Add method info\n",
    "            if method == 'advanced' and 'advanced_info' in comparison:\n",
    "                info = comparison['advanced_info']\n",
    "                steps_text = ', '.join(info['restoration_steps'])\n",
    "                axes[i].text(0.02, 0.98, f\"Steps: {steps_text}\", \n",
    "                           transform=axes[i].transAxes,\n",
    "                           bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7),\n",
    "                           fontsize=8, verticalalignment='top')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n📈 Method Comparison Summary:\")\n",
    "    print(\"1. Classical: Basic enhancement only\")\n",
    "    print(\"2. ML-Guided: Intelligent parameter selection\") \n",
    "    print(\"3. Advanced: Structural repair + quality enhancement\")\n",
    "    print(\"\\n🏆 The Advanced method handles tears, holes, AND quality issues!\")\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ Skipping method comparison (models not available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ced3a2",
   "metadata": {},
   "source": [
    "## 🎯 Step 6: Batch Processing Test\n",
    "\n",
    "Test the advanced system on multiple images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba355409",
   "metadata": {},
   "outputs": [],
   "source": [
    "if advanced_restorer:\n",
    "    # Test batch processing\n",
    "    input_dir = '../data/raw/AI_for_Art_Restoration_2/paired_dataset_art/damaged'\n",
    "    output_dir = '../outputs/advanced_batch_restored'\n",
    "    \n",
    "    if os.path.exists(input_dir):\n",
    "        print(\"🚀 Testing batch advanced restoration...\")\n",
    "        \n",
    "        # Process first 3 images as demo\n",
    "        import glob\n",
    "        files = glob.glob(os.path.join(input_dir, '*.jpg'))[:3]\n",
    "        \n",
    "        results = []\n",
    "        for file_path in files:\n",
    "            try:\n",
    "                output_path = os.path.join(output_dir, f\"advanced_{os.path.basename(file_path)}\")\n",
    "                os.makedirs(output_dir, exist_ok=True)\n",
    "                \n",
    "                restored, info = advanced_restorer.restore_advanced(file_path, output_path)\n",
    "                results.append({\n",
    "                    'file': os.path.basename(file_path),\n",
    "                    'success': True,\n",
    "                    'structural_damage': info['has_structural_repair'],\n",
    "                    'steps': info['restoration_steps']\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                results.append({\n",
    "                    'file': os.path.basename(file_path),\n",
    "                    'success': False,\n",
    "                    'error': str(e)\n",
    "                })\n",
    "        \n",
    "        # Display results\n",
    "        print(\"\\n📊 Batch Processing Results:\")\n",
    "        for result in results:\n",
    "            if result['success']:\n",
    "                status = \"✅ Success\"\n",
    "                extra = f\"Structural repair: {'Yes' if result['structural_damage'] else 'No'}\"\n",
    "            else:\n",
    "                status = \"❌ Failed\"\n",
    "                extra = f\"Error: {result['error']}\"\n",
    "            \n",
    "            print(f\"{result['file']}: {status} - {extra}\")\n",
    "        \n",
    "        success_count = sum(1 for r in results if r['success'])\n",
    "        print(f\"\\n🎯 Batch Success Rate: {success_count}/{len(results)} ({100*success_count/len(results):.1f}%)\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"⚠️ Input directory not found: {input_dir}\")\n",
    "        \n",
    "else:\n",
    "    print(\"⚠️ Advanced restorer not available for batch testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0379346",
   "metadata": {},
   "source": [
    "## 🎓 Summary: Advanced Restoration Capabilities\n",
    "\n",
    "### What We've Built:\n",
    "\n",
    "1. **Structural Damage Detection**:\n",
    "   - Automatic detection of tears, cracks, holes\n",
    "   - Computer vision-based damage analysis\n",
    "   - Quantitative damage assessment\n",
    "\n",
    "2. **Deep Learning Inpainting**:\n",
    "   - Context encoder for missing part reconstruction\n",
    "   - Perceptual loss for realistic results\n",
    "   - Fallback to traditional OpenCV methods\n",
    "\n",
    "3. **Advanced Restoration Pipeline**:\n",
    "   - Combines structural repair + quality enhancement\n",
    "   - Intelligent routing based on damage type\n",
    "   - Preserves all existing ML capabilities\n",
    "\n",
    "### Key Improvements Over Basic Hybrid System:\n",
    "\n",
    "| Feature | Basic Hybrid | Advanced System |\n",
    "|---------|-------------|----------------|\n",
    "| Color correction | ✅ | ✅ |\n",
    "| Sharpening | ✅ | ✅ |\n",
    "| General enhancement | ✅ | ✅ |\n",
    "| **Tear repair** | ❌ | ✅ |\n",
    "| **Hole filling** | ❌ | ✅ |\n",
    "| **Missing part reconstruction** | ❌ | ✅ |\n",
    "| **Structural damage detection** | ❌ | ✅ |\n",
    "| **Complex multi-type damage** | ❌ | ✅ |\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Train the inpainting model** on more data for better results\n",
    "2. **Fine-tune damage detection** parameters for your specific artwork types\n",
    "3. **Collect damaged artwork datasets** with ground truth for training\n",
    "4. **Experiment with different inpainting architectures** (GANs, Transformers)\n",
    "\n",
    "The advanced system now handles the full spectrum of art restoration challenges! 🎨✨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
