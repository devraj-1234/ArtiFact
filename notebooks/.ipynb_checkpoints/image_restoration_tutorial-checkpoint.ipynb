{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d984e8e8",
   "metadata": {},
   "source": [
    "# Step-by-Step Image Restoration Tutorial\n",
    "\n",
    "This notebook provides a beginner-friendly introduction to image restoration techniques. We'll learn:\n",
    "\n",
    "1. What is image restoration?\n",
    "2. Basic techniques for image restoration\n",
    "3. How to apply these techniques to damaged artwork\n",
    "4. How to evaluate the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d28c22",
   "metadata": {},
   "source": [
    "## 1. Introduction to Image Restoration\n",
    "\n",
    "Image restoration is the process of recovering a clean version of a damaged or degraded image. Degradation can happen due to various factors:\n",
    "\n",
    "- Physical damage (cracks, scratches, tears)\n",
    "- Aging (fading, yellowing)\n",
    "- Environmental factors (water damage, mold)\n",
    "- Digital artifacts (noise, blur, compression)\n",
    "\n",
    "Unlike image enhancement, which aims to make an image more visually appealing, restoration specifically focuses on removing degradations to recover the original content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0921634d",
   "metadata": {},
   "source": [
    "## 2. Setup and Imports\n",
    "\n",
    "Let's start by importing the necessary libraries and setting up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "778929ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\R&D Project\\image_processing\\notebooks\n",
      "D:\\R&D Project\\image_processing\n",
      "D:\\R&D Project\\image_processing\\src\\basics\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.getcwd()\n",
    "print(project_root)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "print(project_root)\n",
    "project_root = project_root + \"\\src\\\\basics\"\n",
    "print(project_root)\n",
    "sys.path.append(project_root)\n",
    "print(project_root in sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d5e94fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\R&D Project\\image_processing\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "print(parent_dir)\n",
    "\n",
    "# Add parent directory to Python path to make 'src' module accessible\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Since we've installed the package with pip install -e .\n",
    "# We can directly import from the package\n",
    "from src.basics.basic_fft import convert_to_grayscale, compute_fft, inverse_fft\n",
    "from src.basics.basic_restoration import (\n",
    "    denoise_gaussian, denoise_bilateral, denoise_nlm, enhance_contrast,\n",
    "    enhance_clahe, sharpen_image, remove_scratches, restore_image\n",
    ")\n",
    "\n",
    "# For displaying images\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (15, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f239266",
   "metadata": {},
   "source": [
    "## 3. Loading Sample Images\n",
    "\n",
    "Let's load a damaged image from our dataset for restoration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1465e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 116 damaged images\n",
      "Sample images: ['07_RESTORATION_BEFORE.png', 'alex-before.jpg', 'angel.jpg', 'ArchimedesConservation_05-before.png', 'arena-before.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Path to dataset\n",
    "# Use absolute path to data directory\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "data_path = os.path.join(project_root, \"data/raw/AI_for_Art_Restoration_2/paired_dataset_art\")\n",
    "damaged_dir = os.path.join(data_path, \"damaged\")\n",
    "undamaged_dir = os.path.join(data_path, \"undamaged\")\n",
    "\n",
    "# List available images\n",
    "damaged_files = os.listdir(damaged_dir)\n",
    "undamaged_files = os.listdir(undamaged_dir)\n",
    "print(f\"Found {len(damaged_files)} damaged images\")\n",
    "print(f\"Sample images: {damaged_files[:5]}\")\n",
    "print(f\"Found {len(unamaged_files)} undamaged images\")\n",
    "print(f\"Sample images: {undamaged_files[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4042a3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display multiple images side by side\n",
    "def display_images(images, titles, cmaps=None, figsize=(15, 10)):\n",
    "    \"\"\"Display multiple images for comparison.\"\"\"\n",
    "    n_images = len(images)\n",
    "    fig, axes = plt.subplots(1, n_images, figsize=figsize)\n",
    "    \n",
    "    # If only one image, axes is not a list, so we convert it to a list\n",
    "    if n_images == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, (img, title) in enumerate(zip(images, titles)):\n",
    "        cmap = cmaps[i] if cmaps else ('gray' if len(img.shape) == 2 else None)\n",
    "        axes[i].imshow(img, cmap=cmap)\n",
    "        axes[i].set_title(title)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0f1548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample image (let's use the first one)\n",
    "sample_file = damaged_files[0]  # You can change the index to explore different images\n",
    "damaged_path = os.path.join(damaged_dir, sample_file)\n",
    "\n",
    "# Read the image\n",
    "damaged_img = cv2.imread(damaged_path)\n",
    "\n",
    "# Convert BGR (OpenCV format) to RGB (Matplotlib format) for display\n",
    "damaged_rgb = cv2.cvtColor(damaged_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Try to find the corresponding undamaged (ground truth) image if available\n",
    "undamaged_img = None\n",
    "undamaged_rgb = None\n",
    "undamaged_path = os.path.join(undamaged_dir, sample_file)\n",
    "\n",
    "if os.path.exists(undamaged_path):\n",
    "    undamaged_img = cv2.imread(undamaged_path)\n",
    "    undamaged_rgb = cv2.cvtColor(undamaged_img, cv2.COLOR_BGR2RGB)\n",
    "    print(f\"Found matching undamaged image\")\n",
    "    \n",
    "    # Display both images\n",
    "    display_images(\n",
    "        [damaged_rgb, undamaged_rgb],\n",
    "        [\"Damaged Image\", \"Ground Truth (Undamaged)\"],\n",
    "        figsize=(15, 8)\n",
    "    )\n",
    "else:\n",
    "    print(f\"No matching undamaged image found\")\n",
    "    display_images([damaged_rgb], [\"Damaged Image\"], figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e59337f",
   "metadata": {},
   "source": [
    "## 4. Basic Denoising Techniques\n",
    "\n",
    "Noise is a common type of degradation in images. Let's explore different denoising methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2905e6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply different denoising methods\n",
    "\n",
    "# 1. Gaussian Blur - Good for general noise reduction, but blurs edges\n",
    "denoised_gaussian = denoise_gaussian(damaged_img, kernel_size=5)\n",
    "denoised_gaussian_rgb = cv2.cvtColor(denoised_gaussian, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# 2. Bilateral Filter - Preserves edges while removing noise\n",
    "denoised_bilateral = denoise_bilateral(damaged_img, d=9, sigma_color=75, sigma_space=75)\n",
    "denoised_bilateral_rgb = cv2.cvtColor(denoised_bilateral, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# 3. Non-Local Means - Excellent for preserving details while removing noise\n",
    "denoised_nlm = denoise_nlm(damaged_img, h=10)\n",
    "denoised_nlm_rgb = cv2.cvtColor(denoised_nlm, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display results\n",
    "display_images(\n",
    "    [damaged_rgb, denoised_gaussian_rgb, denoised_bilateral_rgb, denoised_nlm_rgb],\n",
    "    [\"Original\", \"Gaussian Blur\", \"Bilateral Filter\", \"Non-Local Means\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80829347",
   "metadata": {},
   "source": [
    "### Analysis of Denoising Results\n",
    "\n",
    "- **Gaussian Blur**: Simple and fast, but blurs edges and details. Good for removing minor noise.\n",
    "- **Bilateral Filter**: Preserves edges better than Gaussian blur. It considers both spatial proximity and color similarity.\n",
    "- **Non-Local Means**: Often produces the best results, especially for textured areas. It's computationally more expensive but preserves details well.\n",
    "\n",
    "The choice of denoising method depends on the specific type of degradation in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a6230c",
   "metadata": {},
   "source": [
    "## 5. Enhancing Contrast and Color\n",
    "\n",
    "Faded colors and poor contrast are common in degraded artwork. Let's explore techniques to enhance them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c208788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Simple histogram equalization\n",
    "enhanced_contrast = enhance_contrast(damaged_img)\n",
    "enhanced_contrast_rgb = cv2.cvtColor(enhanced_contrast, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# 2. CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "enhanced_clahe = enhance_clahe(damaged_img, clip_limit=2.0, grid_size=(8, 8))\n",
    "enhanced_clahe_rgb = cv2.cvtColor(enhanced_clahe, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display results\n",
    "display_images(\n",
    "    [damaged_rgb, enhanced_contrast_rgb, enhanced_clahe_rgb],\n",
    "    [\"Original\", \"Histogram Equalization\", \"CLAHE Enhancement\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb9f7e7",
   "metadata": {},
   "source": [
    "### Analysis of Enhancement Results\n",
    "\n",
    "- **Histogram Equalization**: Spreads out intensity values, which can help in enhancing contrast globally. However, it may amplify noise and produce unnatural results.\n",
    "- **CLAHE**: Applies histogram equalization in tiles rather than the entire image. This helps in enhancing local contrast while avoiding amplification of noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2313d1",
   "metadata": {},
   "source": [
    "## 6. Removing Scratches and Artifacts\n",
    "\n",
    "Physical damage like scratches and tears are common in old artwork. Let's explore techniques to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7852f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Morphological operations to remove scratches\n",
    "no_scratches = remove_scratches(damaged_img, kernel_size=5)\n",
    "no_scratches_rgb = cv2.cvtColor(no_scratches, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# 2. Sharpening to improve details\n",
    "sharpened = sharpen_image(damaged_img)\n",
    "sharpened_rgb = cv2.cvtColor(sharpened, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display results\n",
    "display_images(\n",
    "    [damaged_rgb, no_scratches_rgb, sharpened_rgb],\n",
    "    [\"Original\", \"Scratch Removal\", \"Sharpened\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaf0c7e",
   "metadata": {},
   "source": [
    "### Analysis of Scratch Removal Results\n",
    "\n",
    "- **Morphological Operations**: Good for removing small scratches and noise by using dilation and erosion operations.\n",
    "- **Sharpening**: Can help recover lost details, but may also enhance noise if not applied carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a8e6b0",
   "metadata": {},
   "source": [
    "## 7. Combining Techniques into a Complete Restoration Pipeline\n",
    "\n",
    "Let's combine multiple techniques to create a full restoration pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f7e675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply our complete restoration pipeline\n",
    "# This will denoise, enhance contrast, and sharpen the image\n",
    "restored_img = restore_image(damaged_img, techniques=['denoise', 'enhance', 'sharpen'])\n",
    "restored_rgb = cv2.cvtColor(restored_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Compare with original and ground truth (if available)\n",
    "if undamaged_rgb is not None:\n",
    "    display_images(\n",
    "        [damaged_rgb, restored_rgb, undamaged_rgb],\n",
    "        [\"Original Damaged\", \"Restored\", \"Ground Truth\"]\n",
    "    )\n",
    "else:\n",
    "    display_images(\n",
    "        [damaged_rgb, restored_rgb],\n",
    "        [\"Original Damaged\", \"Restored\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d446aa75",
   "metadata": {},
   "source": [
    "## 8. Advanced: Inpainting for Missing Areas\n",
    "\n",
    "Inpainting is used to fill in missing or damaged portions of an image. OpenCV provides algorithms to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c2e9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a simple mask for demonstration\n",
    "def create_demo_mask(image, threshold=240):\n",
    "    \"\"\"Create a mask for potentially damaged areas (very bright pixels)\"\"\"\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image.copy()\n",
    "    \n",
    "    _, mask = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY)\n",
    "    return mask\n",
    "\n",
    "# Create a mask for damaged areas\n",
    "mask = create_demo_mask(damaged_img)\n",
    "\n",
    "# Apply inpainting\n",
    "inpainted_telea = cv2.inpaint(damaged_img, mask.astype(np.uint8), 3, cv2.INPAINT_TELEA)\n",
    "inpainted_ns = cv2.inpaint(damaged_img, mask.astype(np.uint8), 3, cv2.INPAINT_NS)\n",
    "\n",
    "# Convert to RGB for display\n",
    "inpainted_telea_rgb = cv2.cvtColor(inpainted_telea, cv2.COLOR_BGR2RGB)\n",
    "inpainted_ns_rgb = cv2.cvtColor(inpainted_ns, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display results\n",
    "display_images(\n",
    "    [damaged_rgb, cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB), inpainted_telea_rgb, inpainted_ns_rgb],\n",
    "    [\"Original\", \"Mask (Damaged Areas)\", \"Fast Marching Method\", \"Navier-Stokes Method\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36282794",
   "metadata": {},
   "source": [
    "### Inpainting Explanation\n",
    "\n",
    "- **Fast Marching Method (TELEA)**: Works by propagating image information from the boundary of the damaged region inward.\n",
    "- **Navier-Stokes Method (NS)**: Based on fluid dynamics, often produces more natural-looking results for larger areas.\n",
    "\n",
    "Note: For real applications, the mask should be carefully created to identify only the damaged areas. This example uses a simple thresholding approach which may not be ideal for all images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0711ff29",
   "metadata": {},
   "source": [
    "## 9. Evaluating Restoration Results\n",
    "\n",
    "If we have ground truth (undamaged) images, we can quantitatively evaluate our restoration results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e1efde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this if we have ground truth\n",
    "if undamaged_img is not None:\n",
    "    # Function to calculate PSNR (Peak Signal-to-Noise Ratio)\n",
    "    def calculate_psnr(img1, img2):\n",
    "        mse = np.mean((img1.astype(np.float64) - img2.astype(np.float64)) ** 2)\n",
    "        if mse == 0:\n",
    "            return float('inf')\n",
    "        return 10 * np.log10((255.0 ** 2) / mse)\n",
    "    \n",
    "    # Function to calculate SSIM (Structural Similarity Index)\n",
    "    def calculate_ssim(img1, img2):\n",
    "        try:\n",
    "            from skimage.metrics import structural_similarity as ssim\n",
    "            return ssim(img1, img2, multichannel=True, data_range=255)\n",
    "        except ImportError:\n",
    "            print(\"scikit-image is required for SSIM calculation\")\n",
    "            return None\n",
    "    \n",
    "    # Calculate metrics\n",
    "    psnr_damaged = calculate_psnr(damaged_img, undamaged_img)\n",
    "    psnr_restored = calculate_psnr(restored_img, undamaged_img)\n",
    "    \n",
    "    ssim_damaged = calculate_ssim(damaged_img, undamaged_img)\n",
    "    ssim_restored = calculate_ssim(restored_img, undamaged_img)\n",
    "    \n",
    "    print(f\"Metrics comparing with ground truth:\")\n",
    "    print(f\"PSNR - Original damaged: {psnr_damaged:.2f} dB, Restored: {psnr_restored:.2f} dB\")\n",
    "    if ssim_damaged is not None and ssim_restored is not None:\n",
    "        print(f\"SSIM - Original damaged: {ssim_damaged:.4f}, Restored: {ssim_restored:.4f}\")\n",
    "        \n",
    "    print(f\"\\nImprovement:\")\n",
    "    print(f\"PSNR improvement: {psnr_restored - psnr_damaged:.2f} dB\")\n",
    "    if ssim_damaged is not None and ssim_restored is not None:\n",
    "        print(f\"SSIM improvement: {ssim_restored - ssim_damaged:.4f}\")\n",
    "else:\n",
    "    print(\"No ground truth image available for quantitative evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7614773",
   "metadata": {},
   "source": [
    "## 10. Trying a Different Image\n",
    "\n",
    "Let's try our restoration pipeline on a different image from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46820204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try another image (select a different index)\n",
    "if len(damaged_files) > 1:\n",
    "    # Choose a different image\n",
    "    sample_file2 = damaged_files[1]  # Change this index to try different images\n",
    "    damaged_path2 = os.path.join(damaged_dir, sample_file2)\n",
    "    \n",
    "    # Read the image\n",
    "    damaged_img2 = cv2.imread(damaged_path2)\n",
    "    \n",
    "    if damaged_img2 is not None:\n",
    "        # Convert BGR to RGB for display\n",
    "        damaged_rgb2 = cv2.cvtColor(damaged_img2, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Apply our restoration pipeline\n",
    "        restored_img2 = restore_image(damaged_img2)\n",
    "        restored_rgb2 = cv2.cvtColor(restored_img2, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Try to find the corresponding undamaged image if available\n",
    "        undamaged_img2 = None\n",
    "        undamaged_rgb2 = None\n",
    "        undamaged_path2 = os.path.join(undamaged_dir, sample_file2)\n",
    "        \n",
    "        if os.path.exists(undamaged_path2):\n",
    "            undamaged_img2 = cv2.imread(undamaged_path2)\n",
    "            undamaged_rgb2 = cv2.cvtColor(undamaged_img2, cv2.COLOR_BGR2RGB)\n",
    "            print(f\"Found matching undamaged image for {sample_file2}\")\n",
    "            \n",
    "            # Display results\n",
    "            display_images(\n",
    "                [damaged_rgb2, restored_rgb2, undamaged_rgb2],\n",
    "                [\"Damaged\", \"Restored\", \"Ground Truth\"]\n",
    "            )\n",
    "        else:\n",
    "            print(f\"No matching undamaged image found for {sample_file2}\")\n",
    "            display_images(\n",
    "                [damaged_rgb2, restored_rgb2],\n",
    "                [\"Damaged\", \"Restored\"]\n",
    "            )\n",
    "    else:\n",
    "        print(f\"Failed to load image {sample_file2}\")\n",
    "else:\n",
    "    print(\"Not enough images in the dataset to try another one\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3194feb",
   "metadata": {},
   "source": [
    "## 11. Conclusion\n",
    "\n",
    "In this tutorial, we've explored several image restoration techniques:\n",
    "\n",
    "1. **Denoising**: Gaussian blur, bilateral filter, and non-local means for noise removal\n",
    "2. **Contrast Enhancement**: Histogram equalization and CLAHE for improving faded images\n",
    "3. **Scratch Removal**: Using morphological operations to reduce physical damage\n",
    "4. **Inpainting**: Filling in missing or heavily damaged regions\n",
    "5. **Full Restoration Pipeline**: Combining multiple techniques for better results\n",
    "\n",
    "Each technique has its strengths and is useful for different types of degradation. In practice, the choice of technique depends on the specific damage in the artwork.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Experiment with different parameter values for each technique\n",
    "2. Try creating custom restoration pipelines for specific types of damage\n",
    "3. Explore advanced techniques like deep learning-based restoration (e.g., U-Net)\n",
    "4. Apply these techniques to other damaged artwork in the dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
